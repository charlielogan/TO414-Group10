---
title: 'TO414 Project 3: Spotify'
author: "Ankita Mohapatra"
date: "4/23/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Objective

Data: In this report, we are working with a Spotify dataset, which contains audio features of around 600k songs released in between 1922 and 2021.

Intended Audience: Music producers, artists, advertisers
Overarching Objective: Predict Danceability, Predict Popularity, Predict if a Song is from a Particular Decade (80â€™s)
Underlying Objective 1 (for music producers and artists): Recognize which aspects correlate to popularity and creating mega hits
Underlying Objective 2 (for Spotify): Help create automatic classification in recommendation algorithms and creating playlists (based on decade for example)
Underlying Objective 3 (for advertisers): Recognize what kind of music works best 

1. Descriptive Analytics: How do audio features differ across decades? How do audio features differ by popularity? 
2. Predictive Analytics: Can we predict danceability? Can we predict popularity? Can we predict if a song is from a particular decade?

Finally, we will identify several applications for the insights presented in this analysis.

# Data Preparation

## Pull & View Main Data
```{r}
spotify <- read.csv("data.csv")
#spotify_by_artist <- read.csv("data_by_artist.csv")
str(spotify)
#summary(spotify)

audio_features <- read.csv("tracks.csv")
```
### Libraries
```{r}
packages <- c("dplyr", "class", "caret", "gmodels", "C50")
lapply(packages, require, character.only = TRUE)
```

### Data Manipulation
Main Data
```{r}
spotify <- subset(spotify, select = -c(id, name, release_date))
spotify$artists <- as.factor(spotify$artists)
spotify$key <- as.factor(spotify$key)
```

Spotify Main Set
```{r}
# Cut year into bins by decade
spotify$decades <- cut(spotify$year, breaks = c(0,1929, 1939, 1949, 1959, 1969, 1979, 1989, 1999, 2009, 2019, Inf), labels = c("20s", "30s", "40s", "50s", "60s", "70s", "80s", "90s", "2000s", "2010s", "2020s"))


# Classify popularity into bins by 75% and 90% percentiles
popularity_threshold <- 42
quantile(spotify$popularity, probs=seq(.1, .9, by = .1))
spotify$hit_class <- ifelse(spotify$popularity >= 56, "mega-hit", ifelse(spotify$popularity > popularity_threshold, "hit", "not hit"))
spotify$hit_class <- as.factor(spotify$hit_class)
# true or false if top 10% or not
spotify$binary_hit_class <- ifelse(spotify$hit_class == "mega-hit", 1, 0)
spotify$binary_hit_class <- as.factor(spotify$binary_hit_class)
table(spotify$hit_class)

```

Audio Features
```{r}
audio_features$release_year <- substr(audio_features$release_date,1,4)
audio_features$release_year <- as.numeric(audio_features$release_year)
audio_features$key <- as.factor(audio_features$key)
boxplot(audio_features$release_year, horizontal = T, main = "Year of Song Release")
audio_features <- subset(audio_features, select = -c(id, name, popularity, artists, id_artists, release_date))
```
```{r}
audio_features <- audio_features %>%
  select(danceability,everything())   #bring `danceability` to first column
```

## Normalized Sets
Normalize method
```{r}
normalize <- function(x){
  return ((x-min(x))/(max(x)-min(x)))
}
  
set.seed(1234)
```

### Spotify set

### Audio Features set
```{r}
audio_featuresMM <- as.data.frame(model.matrix(~.-1,audio_features))  #all columns are numeric
audio_featuresN<- lapply(audio_featuresMM,normalize) #apply normalize() to all columns
audio_featuresN <- as.data.frame(audio_featuresN)
```

## Test & Train
Un-normalized Train & Test Sets
```{r}
test_set <- sample(1:nrow(spotify), 30000)
spotify_train <- spotify[-test_set, ]
spotify_test <- spotify[test_set, ]

```

Normalized Train & Test Sets
```{r}
#audio_features
audio_train <- audio_featuresN[-test_set,]
audio_test <- audio_featuresN[test_set,]

#Response / Labels
audio_train_labs <- audio_featuresN[-test_set,"danceability"]
audio_test_labs <- audio_featuresN[test_set,"danceability"]
```


# General Music Attributes
## By Decade
```{r}
ggplot(spotify, aes(x = decades, y = tempo, fill=decades)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = decades, y = popularity, fill=decades)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = decades, y = valence, fill=decades)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = decades, y = danceability, fill=decades)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = decades, y = loudness, fill=decades)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = decades, y = explicit, fill=decades)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = decades, y = duration_ms, fill=decades)) + 
  geom_bar(stat = "summary", fun = "mean")
```
The graphs show us very interesting trends through the decades. There is a trend towards more loud, high tempo, exlicit, and dancible songs. It also shows that people on Spotify listen to music from the 90's and 2000's the most. 

## By Popularity
```{r}
hist(spotify$popularity)
```
```{r}
ggplot(spotify, aes(x = hit_class, y = danceability, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = acousticness, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = energy, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = explicit, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = instrumentalness, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = liveness, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = loudness, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = mode, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = speechiness, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = tempo, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = valence, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```

Based on the graphs above, we can see that mega-hits typically have higher dancibility, energy, explicitness, and tempo BUT lower acousticness, instrumentalness, liveness, loudness, mode, and valence.
```{r}
sort(table(spotify$artists), decreasing = TRUE)[1:20]
```


# Decade Prediction
## Is the song from the 80s?
```{r}
eighties_train <- subset(spotify_train, select = -c(artists, year, hit_class))
eighties_train$eighties <- ifelse(eighties_train$decades == "80s", 1, 0)
eighties_test$eighties <- ifelse(eighties_test$decades == "80s", 1, 0)
```
First We prepared the train and test data for the 80s prediction test. We removed certain columns from the data set that were irrelevant or dependent on a songs release decade such as artists, year, and hit_class. We then added a boolean column to the data sets indicating whether the song was released in the 1980s or not.


```{r}

eighties_log <- glm(eighties ~ acousticness + danceability + duration_ms + energy + explicit + 
                      instrumentalness + liveness + loudness + mode + 
                      speechiness + tempo + key + instrumentalness*danceability + 
                      duration_ms*acousticness + duration_ms*valence + duration_ms*valence + danceability*instrumentalness, 
                    data = eighties_train, family = "binomial")
summary(eighties_log)

eighties_pred_log <- predict(eighties_log, eighties_test, type = "response")
eighties_pred_log <- ifelse(eighties_pred_log > .23, 1, 0)
summary(eighties_pred_log)
confusionMatrix(as.factor(eighties_pred_log), as.factor(eighties_test$eighties))
```
First we constructed a Logistic Regression to predict whether a song was released in the 80s. The regression resulted in an accuracy of 83.93% and a Kappa value of .2623. The model has many false negatives and false positives and doesn't seem to do a great job distinguishing between 80s music and other decades. Our model suggests that 80s songs have less acousticness, more instrumentals, are more danceable, and have high energy. They also tend to have a faster tempo.

One qualifying factor is that music progression and change isn't discrete even though we are trying to classify music into discrete buckets. For example, a song released in 1979 is likely to sound like a song released in 1980 despite being from a different decade. Additionally, I made the threshold for the log odds value needed to be classified as a 80s song .23 because it maximized the Kappa value for the model. The lower threshold value makes sense because any given song is much more likely to not be from the 80s, so our model has trouble indicating with higher certainty that a song is from the 80s.

```{r}

library(C50)
error_costs = matrix(c(0, 1, 2, 0), nrow = 2)
eighties_dtm <- C5.0(as.factor(eighties) ~ acousticness + danceability + duration_ms + energy + explicit + 
                      instrumentalness + liveness + loudness + mode + 
                      speechiness + tempo + key, data = eighties_train, costs = error_costs)


eighties_pred_dt <- predict(eighties_dtm, eighties_test)
confusionMatrix(as.factor(eighties_pred_dt), as.factor(eighties_test$eighties))

```
Our decision tree model performed slightly better than our logistc regression model. The decision tree has an accuracy of 85.69% and a Kappa value of .2643. Because there are many more non 80s songs than 80s, I added a cost matrix to encouraget the decision tree to minimize false negative responses.

## Which decades are easiest to predict?
```{r}
decade_dtm <- C5.0(decades ~ acousticness + danceability + duration_ms + energy + explicit + 
                      instrumentalness + liveness + loudness + 
                      speechiness + tempo + valence, data = spotify_train)

decades_pred <- predict(decade_dtm, spotify_test, type = "class")
summary(decades_pred)
confusionMatrix(decades_pred, as.factor(spotify_test$decades))
```
The decision tree performed decently well considering how many classes there are and the difficulties in predcting a song's release decade. The model has an accuracy of 34.75% and a Kappa value of .2724. Its interesting to look along the diagnol in the confusion matrix and see that for any given decade of music, the decision tree model predicted the correct decade more than any other individual decade. This indicated that the model is catching onto the trends and differences in music by decade. 

It's also interesting to look at how the decision tree is more likely to mistake a songs decade with an adjacent decade than one further away in time. 
```{r}
fifties_preds <- c(124, 298, 598, 1121, 579, 236, 131, 153, 63, 153, 19)

barplot(fifties_preds, main="Decision Tree Predictions for Songs made in the 50s",
        xlab="Predicted Decade", names.arg=c("20s", "30s", "40s", "50s", "60s", "70s", "80s", "90s", "2000s", "2010s", "2020s"))
```

For example, for all 50s songs, our model accurately predicted 1121 of them. One decade away from the 50s is the 40s and 60s, which recieved 598 and 579 predictions respectively. The general trend is the further away in time a decade is from a songs true decade, the less likely our model is to incorrectly classify it into that decade. this relates back to my comments above about change in music not being discrete but continuous. Songs from the 50s and 60s will sound  more alike than songs from the 50s and 90s, and our model is picking up on that. There are many similarities between the musical decades, and music waves and changes don't necessarily line up with the end of a decade and the start of a new one. That's why its interestign to see and interpret our models results in a histogram rather than just as a binary correct or incorrect prediction.

# Danceability Prediction
Spotify defines danceability as follows:
``Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.
A value of 0.0 is least danceable and 1.0 is most danceable.''

(This was the first model we ran together)
```{r}
dance_model <- lm(danceability ~ tempo + valence + speechiness + 
                    mode + liveness + key + instrumentalness + 
                    explicit + energy + duration_ms + acousticness, data = spotify)
summary(dance_model)
```

By running regression models on the audio features dataset, we can try to predict to what extent the danceability algorithm incorporates the various elements such as those mentioned in the definition above.

```{r}
dm1 <- lm(danceability ~ ., data = audio_train)
```


### ANN

# Popularity Prediction
## What makes a song popular?
### Linear
```{r}
spotify_lin <- lm(popularity ~ valence + speechiness + 
                    mode + liveness + key + instrumentalness + 
                    explicit + energy + duration_ms + danceability + acousticness, data = spotify)
summary(spotify_lin)
```
### Log
```{r}
spotify_log <- glm(popularity_bin ~ valence + speechiness + 
                    liveness + instrumentalness + 
                    energy + duration_ms + danceability + acousticness,
                   data = spotify_train, family = "binomial")
summary(spotify_log)
spotify_pred <- predict(spotify_log, newdata = spotify_test, type = "response")
spotify_pred <- ifelse(spotify_pred >  popularity_threshold/100, 1, 0)
summary(spotify_pred)
CrossTable(x = spotify_pred, y = spotify_test$popularity_bin, prop.chisq=FALSE)
confusionMatrix(spotify_pred, spotify_test$popularity_bin)
```

### log model for hit class (mega-hit vs not) 
```{r}
log_test_labels <- spotify_test$binary_hit_class
log_test <- subset(spotify_test, select=-c(binary_hit_class))
log_train <- subset(spotify_train, select=-c(artists, popularity, year, hit_class))
log_model <- train(binary_hit_class ~ ., data = log_train, method = "glm", family="binomial")
summary(log_model)
```

#### Evaluate Log Model
```{r}
pred <- predict(log_model, log_test)
confusionMatrix(pred, log_test_labels)
```

### KNN
```{r}
knn_train <- subset(log_train, select=-c(decades, key))
knn_test <- subset(log_test, select=-c(artists, popularity, year, decades, hit_class, key))
knn_train <- as.data.frame(lapply(knn_train[1:(ncol(knn_train)-1)], normalize))
knn_test <- as.data.frame(lapply(knn_test[1:ncol(knn_test)], normalize))
knn_model_pred <- knn(train=knn_train, test=knn_test, cl=log_train$binary_hit_class, k=379)
```

#### Evaluate KNN Model
```{r}
confusionMatrix(knn_model_pred, log_test_labels)
```

## Holding artist constant, what makes a song popular?

# Conclusion
