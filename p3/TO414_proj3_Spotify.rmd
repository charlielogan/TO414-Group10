---
title: 'TO414 Project 3: Spotify'
author: "Ankita Mohapatra"
date: "4/23/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Objective

This analysis is of interest to members of the Powerlifting and general strength sports community.

Powerlifting is a sport in which competitors compete to lift the most weight for their class in three separate barbell lifts: the Squat, Bench, and Deadlift. In this report, we will apply analytical methods to examine strength and yield some insights into the underpinnings of strength.

Intended Audience: Members of the powerlifting community: Federation Administrators, Coaches, Competitors, Strength Gym Owners, Powerlifting Gamblers, and Strength sport enthusiasts
Overarching Objective: Predict Strength
Underlying Objective 1 (for all audiences): Recognize which lifter and meet attributes are correlated to strength and success in meet lift attempts
Underlying Objective 2 (for competitors and their coaches): Select a federation that fits your goals, 
Data: Competitor data from powerlifting meets included in the OpenPowerlifting database as of April 2019. OpenPowerlifting is creating a public-domain archive of powerlifting history. 
Procedure: 

1. Descriptive Analytics: How does powerlifting performance vary across gender, age, and weight-based classes? Among the strongest lifters (adjusted for differences in gender, age, and weight), what are the key trends in equipment selection, drug testing, federation association, and meet event? Have lifters gotten stronger over the years? For regular competitors, what are the general strategies in weight jumps across attempts? Texas is a stronghold for Powerlifting - how do Texan lifters stack up against the overall data of lifters in terms of lifter profile and meet performance?
2. Predictive Analytics: Can we use the percent increase between attempts to predict whether the lifter will have a failed or succeeded attempt?  Can we look at trends behind weight jumps and estimate what percent increase the lifter will attempt from Attempt 2 to Attempt 3?**  Can we predict a lifter's best Squat or best Deadlift? 
3. Prescriptive Analytics: Should federations enforce drug testing? To maximize lift total without failing the next lift attempt, what is the optimal % jump in weight that a lifter should attempt?

Finally, we will identify several business management applications for the insights presented in this analysis.




# Data Preparation

## Pull & View Main Data
```{r}
set.seed(1234)
spotify <- read.csv("data.csv")
#spotify_by_artist <- read.csv("data_by_artist.csv")
str(spotify)
#summary(spotify)

audio_features <- read.csv("tracks.csv")
```
### Libraries
```{r}
packages <- c("dplyr", "class", "caret", "gmodels", "C50")
lapply(packages, require, character.only = TRUE)
```

### Data Manipulation
Main Data
```{r}
spotify <- subset(spotify, select = -c(id, name, release_date))
spotify$artists <- as.factor(spotify$artists)
spotify$key <- as.factor(spotify$key)
```

Spotify Main Set
```{r}
# Cut year into bins by decade
spotify$decades <- cut(spotify$year, breaks = c(0,1929, 1939, 1949, 1959, 1969, 1979, 1989, 1999, 2009, 2019, Inf), labels = c("20s", "30s", "40s", "50s", "60s", "70s", "80s", "90s", "2000s", "2010s", "2020s"))


# Classify popularity into bins by 75% and 90% percentiles
popularity_threshold <- 42
quantile(spotify$popularity, probs=seq(.1, .9, by = .1))
spotify$hit_class <- ifelse(spotify$popularity >= 56, "mega-hit", ifelse(spotify$popularity > popularity_threshold, "hit", "not hit"))
spotify$hit_class <- as.factor(spotify$hit_class)
# true or false if top 10% or not
spotify$binary_hit_class <- ifelse(spotify$hit_class == "mega-hit", 1, 0)
spotify$binary_hit_class <- as.factor(spotify$binary_hit_class)
table(spotify$hit_class)

```

Audio Features
```{r}
audio_features$release_year <- substr(audio_features$release_date,1,4)
audio_features$release_year <- as.numeric(audio_features$release_year)
audio_features$key <- as.factor(audio_features$key)
boxplot(audio_features$release_year, horizontal = T, main = "Year of Song Release")
audio_features <- subset(audio_features, select = -c(id, name, popularity, artists, id_artists, release_date))
```
```{r}
audio_features <- audio_features %>%
  select(danceability,everything())   #bring `danceability` to first column
```

## Normalized Sets
Normalize method
```{r}
normalize <- function(x){
  return ((x-min(x))/(max(x)-min(x)))
}

```

### Spotify set

### Audio Features set
```{r}
audio_featuresMM <- as.data.frame(model.matrix(~.-1,audio_features))  #all columns are numeric
audio_featuresN<- lapply(audio_featuresMM,normalize) #apply normalize() to all columns
audio_featuresN <- as.data.frame(audio_featuresN)
```

## Test & Train
Un-normalized Train & Test Sets
```{r}
test_set <- sample(1:nrow(spotify), 30000)
spotify_train <- spotify[-test_set, ]
spotify_test <- spotify[test_set, ]

```

Normalized Train & Test Sets
```{r}
#audio_features
audio_train <- audio_featuresN[-test_set,]
audio_test <- audio_featuresN[test_set,]

#Response / Labels
audio_train_labs <- audio_featuresN[-test_set,"danceability"]
audio_test_labs <- audio_featuresN[test_set,"danceability"]
```


# General Music Attributes
## By Decade
```{r}
ggplot(spotify, aes(x = decades, y = tempo, fill=decades)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = decades, y = popularity, fill=decades)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = decades, y = valence, fill=decades)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = decades, y = danceability, fill=decades)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = decades, y = loudness, fill=decades)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = decades, y = explicit, fill=decades)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = decades, y = duration_ms, fill=decades)) + 
  geom_bar(stat = "summary", fun = "mean")
```
The graphs show us very interesting trends through the decades. There is a trend towards more loud, high tempo, exlicit, and dancible songs. It also shows that people on Spotify listen to music from the 90's and 2000's the most. 

## By Popularity
```{r}
hist(spotify$popularity)
```
```{r}
ggplot(spotify, aes(x = hit_class, y = danceability, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = acousticness, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = energy, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = explicit, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = instrumentalness, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = liveness, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = loudness, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = mode, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = speechiness, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = tempo, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```
```{r}
ggplot(spotify, aes(x = hit_class, y = valence, fill=hit_class)) + 
  geom_bar(stat = "summary", fun = "mean")
```

Based on the graphs above, we can see that mega-hits typically have higher dancibility, energy, explicitness, and tempo BUT lower acousticness, instrumentalness, liveness, loudness, mode, and valence.
```{r}
sort(table(spotify$artists), decreasing = TRUE)[1:20]
```


# Decade Prediction
## Is the song from the 80s?
```{r}
eighties_train <- subset(spotify_train, select = -c(artists, year, hit_class))
eighties_test <- subset(spotify_test, select = -c(artists, year, hit_class))
summary(eighties_train)
summary(eighties_test)
eighties_train$eighties <- ifelse(eighties_train$decades == "80s", 1, 0)
eighties_test$eighties <- ifelse(eighties_test$decades == "80s", 1, 0)
```

```{r}

eighties_log <- glm(eighties ~ acousticness + danceability + duration_ms + energy + explicit + 
                      instrumentalness + liveness + loudness + mode + 
                      speechiness + tempo + key + instrumentalness*danceability + 
                      duration_ms*acousticness + duration_ms*valence + duration_ms*valence + danceability*instrumentalness, 
                    data = eighties_train, family = "binomial")
summary(eighties_log)

eighties_pred_log <- predict(eighties_log, eighties_test, type = "response")
eighties_pred_log <- ifelse(eighties_pred_log > .23, 1, 0)
summary(eighties_pred_log)
confusionMatrix(as.factor(eighties_pred_log), as.factor(eighties_test$eighties))
```

```{r}

library(C50)

eighties_dtm <- C5.0(as.factor(eighties) ~ acousticness + danceability + duration_ms + energy + explicit + 
                      instrumentalness + liveness + loudness + mode + 
                      speechiness + tempo + key + 
                      +valence, data = eighties_train)



eighties_pred_dt <- predict(eighties_dtm, eighties_test, type = "class")
confusionMatrix(as.factor(eighties_pred_dt), as.factor(eighties_test$eighties))

```

## Which decades are easiest to predict?
```{r}
decade_dtm <- C5.0(decades ~ acousticness + danceability + duration_ms + energy + explicit + 
                      instrumentalness + liveness + loudness + 
                      speechiness + tempo + valence, data = spotify_train)

decades_pred <- predict(decade_dtm, spotify_test, type = "class")
summary(decades_pred)
confusionMatrix(decades_pred, as.factor(spotify_test$decades))
```


# Danceability Prediction
Spotify defines danceability as follows:
``Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.
A value of 0.0 is least danceable and 1.0 is most danceable.''

(This was the first model we ran together)
```{r}
dance_model <- lm(danceability ~ tempo + valence + speechiness + 
                    mode + liveness + key + instrumentalness + 
                    explicit + energy + duration_ms + acousticness, data = spotify)
summary(dance_model)
```

By running regression models on the audio features dataset, we can try to predict to what extent the danceability algorithm incorporates the various elements such as those mentioned in the definition above.

```{r}
dm1 <- lm(danceability ~ ., data = audio_train)
```

# Popularity Prediction
## What Makes a Song Popular?
Though the artist or record label may be a driving factor in the popularity of a song, predicting popularity based on song attributes alone could be very valuable information for an artist, someone who works for an artist, or a music streaming service. To find the tendencies of the most popular songs and try to see if we can classify them, we broke the data set into 2 classes: "mega-hit", a song in the top 10% of popularity on Spotify, and all other songs. Popularity of songs is never guaranteed even with multi-million dollar marketing budgets for popular artists, so any insight into what interior attributes make a song popular can be a strategic advantage. 

### Log Model for Hit Classification (mega-hit vs not) 
We can start by training a logistic regression model to classify songs as mega-hits vs non-mega-hits.
```{r, cache=TRUE}
log_test_labels <- spotify_test$binary_hit_class
log_test <- subset(spotify_test, select=-c(binary_hit_class))
log_train <- subset(spotify_train, select=-c(artists, popularity, year, hit_class))
log_model <- train(binary_hit_class ~ ., data = log_train, method = "glm", family="binomial")
summary(log_model)
```
The coefficients and p-values tell us that songs that are highly danceable, not too long and have lower energy, speechiness and liveness. We can use predict and the model generated by the train fucntion to make a classification for our test set.
#### Evaluate Log Model
```{r}
pred <- predict(log_model, log_test)
confusionMatrix(pred, log_test_labels)
```
The logistic model attained an overall accuracy of ~91%, though given the vast majority of the elements in the test set were not hits, the overall accuracy is less descriptive than we'd like. Though classifying a song as not a mega-hit is still useful, our main prediction of interest is to find which songs will be mega-hits. Of the 1057 songs that our model classified as a mega-hit, it successfully classified 721 of them (~68%).
### KNN
Another good option specifically for classifying human behavioral tendencies (popular culture in this case) is a K-nearest neighbors algorithm. To predict a new song's popularity, the algorithm will search for songs with similar attributes and make a classification based on the popularity of those nearby songs. We normalize this data to be on a 0 to 1 scale so as not to overemphasize inputs with larger magnitude. 
```{r}
knn_train <- subset(log_train, select=-c(decades, key))
knn_test <- subset(log_test, select=-c(artists, popularity, year, decades, hit_class, key))
knn_train <- as.data.frame(lapply(knn_train[1:(ncol(knn_train)-1)], normalize))
knn_test <- as.data.frame(lapply(knn_test[1:ncol(knn_test)], normalize))
knn_model_pred <- knn(train=knn_train, test=knn_test, cl=log_train$binary_hit_class, k=95)
```

#### Evaluate KNN Model
```{r}
confusionMatrix(knn_model_pred, log_test_labels)
```

The KNN model also faired decently well in classifying "mega-hit" songs, having a slightly lower accuracy than the log model at ~90%. Additionally the KNN was less willing to make a mega-hit classification, which is reasonable due to the significantly higher amount of non hits in the data set. The KNN still correctly classified 458/692 "mega-hit" classifications, about 66%. The model improved slightly by dropping K, the threshold for making a classification, to 1/4 of the square root of input rows, which is the typical starting point for a K value. Overall, the logistic model was more successful in completing the task we set out to accomplish in building these models: correctly predict which songs have the potential to become extremely popular. 
## Holding artist constant, what makes a song popular?

# Conclusion
